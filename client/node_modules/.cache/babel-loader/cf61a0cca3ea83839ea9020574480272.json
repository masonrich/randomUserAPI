{"ast":null,"code":"/*\r\n    This function reaches to the node backend and fetches the user\r\n    list provided by the randomuser.me API call. Randomuser.me has\r\n    an API restriction of grabbing only 5000 users at once. In order\r\n    to grab the list of 7000, I make two calls to this API, grabbing\r\n    3500 at time. It seemed more intuitive to do it this way, rather \r\n    then calling the API for every page. Maybe a more optimal way \r\n    would be to fetch 1000 users at time and then call it when needed?\r\n*/\nasync function getUserList() {\n  var fullUserList = [];\n  var seed = \"abc\"; //get the first 3500 users\n\n  await fetch(\"/api/getList/\" + seed).then(res => res.json()).then(list => {\n    fullUserList = list;\n  }); //set a new seed to create new, consistent data\n\n  seed = \"def\"; //get the next 3500 users\n\n  await fetch(\"/api/getList/\" + seed).then(res => res.json()).then(list => {\n    fullUserList.push.apply(fullUserList, list); //combine both API call user lists\n\n    fullUserList.sort((a, b) => a.name.last > b.name.last ? 1 : -1);\n  });\n  return fullUserList;\n}\n\nexport { getUserList };","map":{"version":3,"sources":["C:/Users/mason/Projects/clozd_assignment/client/src/App/api/users.js"],"names":["getUserList","fullUserList","seed","fetch","then","res","json","list","push","apply","sort","a","b","name","last"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAeA,WAAf,GAA6B;AAC3B,MAAIC,YAAY,GAAG,EAAnB;AACA,MAAIC,IAAI,GAAG,KAAX,CAF2B,CAI3B;;AACA,QAAMC,KAAK,CAAC,kBAAkBD,IAAnB,CAAL,CACHE,IADG,CACGC,GAAD,IAASA,GAAG,CAACC,IAAJ,EADX,EAEHF,IAFG,CAEGG,IAAD,IAAU;AACdN,IAAAA,YAAY,GAAGM,IAAf;AACD,GAJG,CAAN,CAL2B,CAW3B;;AACAL,EAAAA,IAAI,GAAG,KAAP,CAZ2B,CAc3B;;AACA,QAAMC,KAAK,CAAC,kBAAkBD,IAAnB,CAAL,CACHE,IADG,CACGC,GAAD,IAASA,GAAG,CAACC,IAAJ,EADX,EAEHF,IAFG,CAEGG,IAAD,IAAU;AACdN,IAAAA,YAAY,CAACO,IAAb,CAAkBC,KAAlB,CAAwBR,YAAxB,EAAsCM,IAAtC,EADc,CAC+B;;AAC7CN,IAAAA,YAAY,CAACS,IAAb,CAAkB,CAACC,CAAD,EAAIC,CAAJ,KAAWD,CAAC,CAACE,IAAF,CAAOC,IAAP,GAAcF,CAAC,CAACC,IAAF,CAAOC,IAArB,GAA4B,CAA5B,GAAgC,CAAC,CAA9D;AACD,GALG,CAAN;AAOA,SAAOb,YAAP;AACD;;AAED,SAASD,WAAT","sourcesContent":["/*\r\n    This function reaches to the node backend and fetches the user\r\n    list provided by the randomuser.me API call. Randomuser.me has\r\n    an API restriction of grabbing only 5000 users at once. In order\r\n    to grab the list of 7000, I make two calls to this API, grabbing\r\n    3500 at time. It seemed more intuitive to do it this way, rather \r\n    then calling the API for every page. Maybe a more optimal way \r\n    would be to fetch 1000 users at time and then call it when needed?\r\n*/\r\nasync function getUserList() {\r\n  var fullUserList = [];\r\n  var seed = \"abc\";\r\n\r\n  //get the first 3500 users\r\n  await fetch(\"/api/getList/\" + seed)\r\n    .then((res) => res.json())\r\n    .then((list) => {\r\n      fullUserList = list;\r\n    });\r\n\r\n  //set a new seed to create new, consistent data\r\n  seed = \"def\";\r\n\r\n  //get the next 3500 users\r\n  await fetch(\"/api/getList/\" + seed)\r\n    .then((res) => res.json())\r\n    .then((list) => {\r\n      fullUserList.push.apply(fullUserList, list); //combine both API call user lists\r\n      fullUserList.sort((a, b) => (a.name.last > b.name.last ? 1 : -1));\r\n    });\r\n\r\n  return fullUserList;\r\n}\r\n\r\nexport { getUserList };\r\n"]},"metadata":{},"sourceType":"module"}